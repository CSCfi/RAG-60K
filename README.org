#+TITLE: RAG-60K
#+AUTHOR: Shanshan Wang
#+OPTIONS: toc:nil
#+OPTIONS: num:nil

#+ATTR_HTML: :style display:block; margin:0 auto; width:50%;
[[file:./Faiss_DDP.jpg]]

\\

* Introduction to RAG

Retrieval-Augmented Generation (RAG) is a powerful technique that enhances language models by incorporating external knowledge retrieval. Instead of relying solely on pre-trained knowledge, RAG fetches relevant information from a document store or a vector database, improving response accuracy and reducing hallucinations. This approach is particularly beneficial for applications like question-answering, summarization, and chatbot development, where real-time and up-to-date information is crucial. RAG has gained popularity because it effectively bridges the gap between retrieval-based and generative models. It allows models to provide factually accurate answers without the need for frequent retraining. Additionally, RAG enhances interpretability, as users can trace responses back to retrieved documents.

* Motivation of RAG-60K
Several frameworks have emerged to streamline the implementation of RAG pipelines, including LangChain and LlamaIndex. While both offer great abstraction layers, they face limitations when scaling to massive datasets.

Most scalable solutions available today require paid services, such as Anyscale—a platform that helps developers and organizations build, deploy, and manage scalable AI and machine learning applications using Ray—and commercial vector stores e.g., Pinecone, Weaviate, and AWS OpenSearch. Many paid solutions offer scalability but at the cost of vendor lock-in and high operational expenses.

This repository provides an alternative method to implement a scalable RAG pipeline from scratch by leveraging PyTorch Distributed Data Parallel (DDP) for efficient parallel processing across multiple GPUs and Faiss-GPU, which utilizes Facebook AI Similarity Search (Faiss) with GPU acceleration to perform efficient nearest neighbor search at scale. The figure above illustrates the complete workflow of our approach, highlighting how we distribute data and efficiently build the Faiss vector store.

* Data
To download the data used in this project, please refer to the [[https://github.com/CSCfi/RAG-60K/tree/main/data][data]] folder under this repo.

* Usage

** Generate embedding vectors

  #+BEGIN_SRC bash
    sbatch run_ingest.sh
  #+END_SRC

** Merge the embedding vectors to Faiss vector store
#+begin_src bash
 sbatch run_merge.sh
#+end_src

** Retrieval
*** Using GPT models from openAI
During the retrieval process, we use 1 gpu interactively
#+begin_src bash
    srun --account=project_462000824 --partition=small-g --ntasks=1 --cpus-per-task=7 --gpus-per-node=1 --mem=60G --time=00:30:00 --nodes=1 --pty bash

    module purge
    module use /appl/local/csc/modulefiles
    module load pytorch
    python retriever_faiss.py
#+end_src

*** Using open source Llama models
During the retrieval process, we use 1 gpu interactively
#+begin_src bash
    srun --account=project_462000824 --partition=small-g --ntasks=1 --cpus-per-task=7 --gpus-per-node=1 --mem=60G --time=00:30:00 --nodes=1 --pty bash

    module purge
    module use /appl/local/csc/modulefiles
    module load pytorch
    export HF_HOME=/scratch/project_465000454/${USER}/hf-cache
    huggingface-cli login # put your token in the terminal
    python retriever_faiss.py
#+end_src
** Notes

- The scripts are made for LUMI, and one naturally has to edit them to set the appropriate project number and paths.

- CSC modulefiles and CSC preinstalled pytorch cover most of the libraries needed to run the codes in this project, except langchain library. One can set up their own environment and install langchain and other libraries if needed
#+begin_src bash
  python3 -m venv --system-site-packages venv
  source venv/bin/activate
  pip install langchain
#+end_src

- Faiss can do more than retrieving one query, with the multiple gpu support, it can handle tens of thousands of queries like stated in this [[https://github.com/facebookresearch/faiss/blob/main/tutorial/python/5-Multiple-GPUs.py][website]].

* License
  MIT License
